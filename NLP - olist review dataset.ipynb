{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - olist review dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will go back to the Olist dataset. Run the code below to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, max_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soutobias/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (1,2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>length_review</th>\n",
       "      <th>review_score</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-18 00:00:00</td>\n",
       "      <td>2018-01-18 21:46:59</td>\n",
       "      <td>41dcb106f807e993532d446263290104</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-01-11 15:30:49</td>\n",
       "      <td>2018-01-11 15:47:59</td>\n",
       "      <td>2018-01-12 21:57:22</td>\n",
       "      <td>2018-01-17 18:42:41</td>\n",
       "      <td>2018-02-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
       "      <td>informatica_acessorios</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-10 00:00:00</td>\n",
       "      <td>2018-03-11 03:05:13</td>\n",
       "      <td>8a2e7ef9053dea531e4dc76bd6d853e6</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-28 12:25:19</td>\n",
       "      <td>2018-02-28 12:48:39</td>\n",
       "      <td>2018-03-02 19:08:15</td>\n",
       "      <td>2018-03-09 23:17:20</td>\n",
       "      <td>2018-03-14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
       "      <td>informatica_acessorios</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-17 00:00:00</td>\n",
       "      <td>2018-02-18 14:36:24</td>\n",
       "      <td>e226dfed6544df5b7b87a48208690feb</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-03 09:56:22</td>\n",
       "      <td>2018-02-03 10:33:41</td>\n",
       "      <td>2018-02-06 16:18:28</td>\n",
       "      <td>2018-02-16 17:28:48</td>\n",
       "      <td>2018-03-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>ferramentas_jardim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>2017-04-21 00:00:00</td>\n",
       "      <td>2017-04-21 22:02:06</td>\n",
       "      <td>de6dff97e5f1ba84a3cd9a3bc97df5f6</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-04-09 17:41:13</td>\n",
       "      <td>2017-04-09 17:55:19</td>\n",
       "      <td>2017-04-10 14:24:47</td>\n",
       "      <td>2017-04-20 09:08:35</td>\n",
       "      <td>2017-05-10 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2018-03-02 10:26:53</td>\n",
       "      <td>5986b333ca0d44534a156a52a8e33a83</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-10 10:59:03</td>\n",
       "      <td>2018-02-10 15:48:21</td>\n",
       "      <td>2018-02-15 19:36:14</td>\n",
       "      <td>2018-02-28 16:33:35</td>\n",
       "      <td>2018-03-09 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id length_review review_score  \\\n",
       "0  7bc2406110b926393aa56f80a40eba40             0            4   \n",
       "1  80e641a11e56f04c1ad469d5645fdfde             0            5   \n",
       "2  228ce5500dc1d8e020d8d1322874b6f0             0            5   \n",
       "3  e64fb393e7b32834bb789ff8bb30750e            37            5   \n",
       "4  f7c4243c7fe1938f181bec41a392bdeb           100            5   \n",
       "\n",
       "                           order_id   product_category_name  \\\n",
       "0  73fc7af87114b39712e6da79b0a377eb           esporte_lazer   \n",
       "1  a548910a1c6147796b98fdf73dbeba33  informatica_acessorios   \n",
       "2  f9e4b658b201a9f2ecdecbb34bed034b  informatica_acessorios   \n",
       "3  658677c97b385a9be170737859d3511b      ferramentas_jardim   \n",
       "4  8e6bfb81e283fa7e4f11123a3fb894f1           esporte_lazer   \n",
       "\n",
       "  review_comment_title                             review_comment_message  \\\n",
       "0                  NaN                                                NaN   \n",
       "1                  NaN                                                NaN   \n",
       "2                  NaN                                                NaN   \n",
       "3                  NaN              Recebi bem antes do prazo estipulado.   \n",
       "4                  NaN  Parabéns lojas lannister adorei comprar pela I...   \n",
       "\n",
       "  review_creation_date review_answer_timestamp  \\\n",
       "0  2018-01-18 00:00:00     2018-01-18 21:46:59   \n",
       "1  2018-03-10 00:00:00     2018-03-11 03:05:13   \n",
       "2  2018-02-17 00:00:00     2018-02-18 14:36:24   \n",
       "3  2017-04-21 00:00:00     2017-04-21 22:02:06   \n",
       "4  2018-03-01 00:00:00     2018-03-02 10:26:53   \n",
       "\n",
       "                        customer_id order_status order_purchase_timestamp  \\\n",
       "0  41dcb106f807e993532d446263290104    delivered      2018-01-11 15:30:49   \n",
       "1  8a2e7ef9053dea531e4dc76bd6d853e6    delivered      2018-02-28 12:25:19   \n",
       "2  e226dfed6544df5b7b87a48208690feb    delivered      2018-02-03 09:56:22   \n",
       "3  de6dff97e5f1ba84a3cd9a3bc97df5f6    delivered      2017-04-09 17:41:13   \n",
       "4  5986b333ca0d44534a156a52a8e33a83    delivered      2018-02-10 10:59:03   \n",
       "\n",
       "     order_approved_at order_delivered_carrier_date  \\\n",
       "0  2018-01-11 15:47:59          2018-01-12 21:57:22   \n",
       "1  2018-02-28 12:48:39          2018-03-02 19:08:15   \n",
       "2  2018-02-03 10:33:41          2018-02-06 16:18:28   \n",
       "3  2017-04-09 17:55:19          2017-04-10 14:24:47   \n",
       "4  2018-02-10 15:48:21          2018-02-15 19:36:14   \n",
       "\n",
       "  order_delivered_customer_date order_estimated_delivery_date  \n",
       "0           2018-01-17 18:42:41           2018-02-02 00:00:00  \n",
       "1           2018-03-09 23:17:20           2018-03-14 00:00:00  \n",
       "2           2018-02-16 17:28:48           2018-03-09 00:00:00  \n",
       "3           2017-04-20 09:08:35           2017-05-10 00:00:00  \n",
       "4           2018-02-28 16:33:35           2018-03-09 00:00:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/olist_review.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review_score'] = pd.to_numeric(data['review_score'], errors='coerce', downcast='integer')\n",
    "data.dropna(subset=['review_comment_message', 'review_score'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string \n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.str.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "def lower_text(text):\n",
    "    return text.str.lower()\n",
    "\n",
    "def remove_numbers(text):\n",
    "    numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 0]\n",
    "    for number in numbers:\n",
    "        text = text.replace(number, '')\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('portuguese')\n",
    "    word_tokens = word_tokenize(text)\n",
    "    text = [w for w in word_tokens if not w in stop_words] \n",
    "    return ' '.join(text)\n",
    "\n",
    "def lemm_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = word_tokenize(text) \n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return ' '.join(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-bcf356a75a24>:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  text = text.str.replace(punctuation, '')\n"
     ]
    }
   ],
   "source": [
    "data['clean_text'] = remove_punctuation(data['review_comment_message'])\n",
    "data['clean_text'] = lower_text(data['clean_text'])\n",
    "data['clean_text'] = remove_numbers(data['clean_text'])\n",
    "data['clean_text'] = data['clean_text'].map(lambda x: remove_stopwords(x))\n",
    "data['clean_text'] = data['clean_text'].map(lambda x: lemm_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['clean_text']\n",
    "y = data['review_score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "tfid\n",
      "{'nb__alpha': 0.1, 'tfidf__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "parameters_1 = {\n",
    "    'tfidf__ngram_range': ((1,1), (2,2)),\n",
    "    'nb__alpha': (0.01,0.1,1),}\n",
    "\n",
    "grid_search_1 = GridSearchCV(pipeline_1, parameters_1, n_jobs=-1, \n",
    "                           verbose=1, scoring = \"accuracy\", \n",
    "                           refit=True, cv=5)\n",
    "\n",
    "grid_search_1.fit(data['clean_text'], y)\n",
    "\n",
    "print('tfid')\n",
    "print(grid_search_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('nb', MultinomialNB(alpha=0.1))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = grid_search_1.best_estimator_\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4830813151903116"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('bom', 1508.9156288751578), ('prazo', 1365.9637110282197), ('produto', 1304.8779278098755), ('ante', 1067.9345446655702), ('entrega', 1011.8755650669912), ('chegou', 944.0049783139564), ('entregue', 681.8583748624602), ('tudo', 568.497316523499), ('bem', 528.800970440287), ('gostei', 508.691543533337)]\n",
      "Topic 1:\n",
      "[('produto', 721.1735550509152), ('recebi', 619.5945462307276), ('excelente', 603.665498251648), ('ótimo', 600.1042737751467), ('recomendo', 540.2638271814518), ('boa', 398.2980100096355), ('ainda', 349.58384670222364), ('comprei', 330.2737566478495), ('qualidade', 317.6694664510917), ('otimo', 302.6415787850103)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soutobias/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer().fit(X_train)\n",
    "\n",
    "data_vectorized = vectorizer.transform(X_train)\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=2).fit(data_vectorized)\n",
    "\n",
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])\n",
    "\n",
    "print_topics(lda_model, vectorizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
